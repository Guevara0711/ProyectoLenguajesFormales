{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizador Sintactico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sintaxis correcta\n",
      "AST:\n",
      "  hello\n",
      "  hi\n",
      "  how\n",
      "  hello\n",
      "  como\n",
      "  que\n",
      "  quien\n",
      "  hola\n",
      "  como\n",
      "  how\n"
     ]
    }
   ],
   "source": [
    "def abrir_archivo(file):\n",
    "    with open(file) as archivo:\n",
    "        return archivo.read()\n",
    "#print(abrir_archivo('pruebadetexto.txt'))\n",
    "\n",
    "#identificadores para palabras en ingles y español\n",
    "En_words = [\"hi\", \"hello\", \"hey\", \"goodbye\", \"bye\", \"see you later\", \"see you soon\", \"see y\", \"good morning\", \"good afternoon\", \"good evening\", \"good night\"]\n",
    "\n",
    "Es_words = [\"hola\", \"buenos dias\", \"buenas tardes\", \"buenas noches\", \"adios\", \"hasta luego\", \"hasta pronto\", \"hasta mañana\", \"hasta la vista\", \"hasta la proxima\"]\n",
    "\n",
    "En_questions = [\"what\", \"who\", \"when\", \"where\", \"why\", \"how\", \"which\", \"why\", \"how\"]\n",
    "\n",
    "Es_questions = [\"que\", \"quien\", \"cuando\", \"donde\", \"porque\", \"como\", \"cual\", \"por que\"]\n",
    "\n",
    "signos_puntuacion = [',', '.', ';', ':', '!', '?', '-', '(', ')', '[', ']', '{', '}', '\"', \"'\", '/', '\\\\', '@', '#', '$', '%', '&', '*', '+', '<', '>', '=', '|', '^', '_', '`', '~', '¡', '¿']\n",
    "\n",
    "#lista de numeros\n",
    "numeros = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "#lista de letras \n",
    "abecedario = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"ñ\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\",\"Ñ\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "espacios = [\" \"]\n",
    "\n",
    "#lista de tokens\n",
    "tokens = []\n",
    "\n",
    "#lista de errores\n",
    "errores = []\n",
    "\n",
    "\n",
    "with open(\"pruebadetexto.txt\", \"r\") as f:\n",
    "    archivo = f.read()\n",
    "def tokenizador(archivo):\n",
    "    tokens = []\n",
    "    errores = []\n",
    "    i = 0\n",
    "    while i < len(archivo):\n",
    "        if archivo[i] in abecedario:\n",
    "            palabra = \"\"\n",
    "            while i < len(archivo) and archivo[i] in abecedario:\n",
    "                palabra += archivo[i]\n",
    "                i += 1\n",
    "            if palabra in En_words:\n",
    "                tokens.append((\"Palabra en ingles\", palabra))\n",
    "            elif palabra in Es_words:\n",
    "                tokens.append((\"Palabra en español\", palabra))\n",
    "            elif palabra in En_questions:\n",
    "                tokens.append((\"Pregunta en ingles\", palabra))\n",
    "            elif palabra in Es_questions:\n",
    "                tokens.append((\"Pregunta en español\", palabra))\n",
    "            else:\n",
    "                tokens.append((\"Palabra\", palabra))\n",
    "        elif archivo[i] in numeros:\n",
    "            numero = \"\"\n",
    "            while i < len(archivo) and archivo[i] in numeros:\n",
    "                numero += archivo[i]\n",
    "                i += 1\n",
    "            tokens.append((\"Numero\", numero))\n",
    "        elif archivo[i] in signos_puntuacion:\n",
    "            tokens.append((\"Signo de puntuacion\", archivo[i]))\n",
    "            i += 1\n",
    "        else:\n",
    "            errores.append((\"Error\", archivo[i]))\n",
    "            i += 1\n",
    "    return tokens, errores\n",
    "\n",
    "tokens, errores = tokenizador(archivo)\n",
    "\n",
    "with open(\"resultado.txt\", \"w\") as f:\n",
    "    f.write(\"Tokens encontrados: \\n\")\n",
    "    for token_type, token in tokens:\n",
    "        f.write(f\"{token_type}: {token} \\n\")\n",
    "    f.write(\"Errores encontrados: \\n\")\n",
    "    for error_type, error in errores:\n",
    "        f.write(f\"{error_type}: {error} \\n\")\n",
    "\n",
    "#análisis sintáctico\n",
    "class AnalizadorSintactico:\n",
    "    def __init__(self):\n",
    "        self.tokens = []\n",
    "        self.errores = []\n",
    "        self.posicion = 0\n",
    "\n",
    "    def analizar(self, archivo):\n",
    "        self.tokens, self.errores = tokenizador(archivo)\n",
    "        self.posicion = 0\n",
    "        self.verificar_sintaxis()\n",
    "\n",
    "    def verificar_sintaxis(self):\n",
    "        ast = self.parse()\n",
    "        if ast == \"Error\":\n",
    "            print(\"Error de sintaxis\")\n",
    "        else:\n",
    "            print(\"Sintaxis correcta\")\n",
    "            print(\"AST:\")\n",
    "            self.print_ast(ast, 0)\n",
    "\n",
    "    def parse(self):\n",
    "        node = []\n",
    "        token = self.get_next_token()\n",
    "        while token is not None and token[0] in [\"Palabra en ingles\", \"Palabra en español\", \"Pregunta en ingles\", \"Pregunta en español\"]:\n",
    "            node.append(token[1])\n",
    "            token = self.get_next_token()\n",
    "        if len(node) == 0:\n",
    "            return \"Error\"\n",
    "        return node\n",
    "       \n",
    "    def get_next_token(self):\n",
    "        while self.posicion < len(self.tokens):\n",
    "            token = self.tokens[self.posicion]\n",
    "            if token[0] in [\"Palabra en ingles\", \"Palabra en español\", \"Pregunta en ingles\", \"Pregunta en español\"]:\n",
    "                self.posicion += 1\n",
    "                return token\n",
    "            else:\n",
    "                self.posicion += 1\n",
    "        return None\n",
    "           \n",
    "    def print_ast(self, node, indent):\n",
    "        if isinstance(node, str):\n",
    "            print(\" \" * indent + node)\n",
    "        else:\n",
    "            for child in node:\n",
    "                self.print_ast(child, indent + 2)\n",
    "   \n",
    "analizador = AnalizadorSintactico()\n",
    "analizador.analizar(archivo)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
