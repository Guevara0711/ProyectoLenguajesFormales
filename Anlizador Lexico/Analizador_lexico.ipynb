{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola Mundo! 1 , . : ; print init if #\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod \n",
      "tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, \n",
      "quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. \n",
      "Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu \n",
      "fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident , sunt in \n",
      "culpa qui officia deserunt mollit anim id est laborum. hi what \n"
     ]
    }
   ],
   "source": [
    "def abrir_archivo(file):\n",
    "    with open(file) as archivo:\n",
    "        return archivo.read()\n",
    "print(abrir_archivo('pruebadetexto.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras reservadas\n",
    "palabras_reservadas = [\"iridiodeshecho\", \"Iridiodeshecho\", ]\n",
    "\n",
    "#identificadores para palabras en ingles y español\n",
    "En_words = [\"hi\", \"hello\", \"hey\", \"goodbye\", \"bye\", \"see you later\", \"see you soon\", \"see y\", \"good morning\", \"good afternoon\", \"good evening\", \"good night\"]\n",
    "\n",
    "Es_words = [\"hola\", \"buenos dias\", \"buenas tardes\", \"buenas noches\", \"adios\", \"hasta luego\", \"hasta pronto\", \"hasta mañana\", \"hasta la vista\", \"hasta la proxima\"]\n",
    "\n",
    "En_questions = [\"what\", \"who\", \"when\", \"where\", \"why\", \"how\", \"which\", \"why\", \"how\"]\n",
    "\n",
    "Es_questions = [\"que\", \"quien\", \"cuando\", \"donde\", \"porque\", \"como\", \"cual\", \"por que\"]\n",
    "\n",
    "signos_puntuacion = [',', '.', ';', ':', '!', '?', '-', '(', ')', '[', ']', '{', '}', '\"', \"'\", '/', '\\\\', '@', '#', '$', '%', '&', '*', '+', '<', '>', '=', '|', '^', '_', '`', '~', '¡', '¿']\n",
    "\n",
    "#lista de numeros\n",
    "numeros = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "#lista de letras \n",
    "abecedario = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"ñ\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\",\"Ñ\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "#lista de tokens\n",
    "tokens = []\n",
    "\n",
    "#lista de errores\n",
    "errores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens encontrados:\n",
      "[('Palabra', 'Hola'), ('Palabra', 'Mundo'), ('Signo de puntuacion', '!'), ('Numero', '1'), ('Signo de puntuacion', ','), ('Signo de puntuacion', '.'), ('Signo de puntuacion', ':'), ('Signo de puntuacion', ';'), ('Palabra', 'print'), ('Palabra', 'init'), ('Palabra', 'if'), ('Signo de puntuacion', '#'), ('Palabra', 'Lorem'), ('Palabra', 'ipsum'), ('Palabra', 'dolor'), ('Palabra', 'sit'), ('Palabra', 'amet'), ('Signo de puntuacion', ','), ('Palabra', 'consectetur'), ('Palabra', 'adipiscing'), ('Palabra', 'elit'), ('Signo de puntuacion', ','), ('Palabra', 'sed'), ('Palabra', 'do'), ('Palabra', 'eiusmod'), ('Palabra', 'tempor'), ('Palabra', 'incididunt'), ('Palabra', 'ut'), ('Palabra', 'labore'), ('Palabra', 'et'), ('Palabra', 'dolore'), ('Palabra', 'magna'), ('Palabra', 'aliqua'), ('Signo de puntuacion', '.'), ('Palabra', 'Ut'), ('Palabra', 'enim'), ('Palabra', 'ad'), ('Palabra', 'minim'), ('Palabra', 'veniam'), ('Signo de puntuacion', ','), ('Palabra', 'quis'), ('Palabra', 'nostrud'), ('Palabra', 'exercitation'), ('Palabra', 'ullamco'), ('Palabra', 'laboris'), ('Palabra', 'nisi'), ('Palabra', 'ut'), ('Palabra', 'aliquip'), ('Palabra', 'ex'), ('Palabra', 'ea'), ('Palabra', 'commodo'), ('Palabra', 'consequat'), ('Signo de puntuacion', '.'), ('Palabra', 'Duis'), ('Palabra', 'aute'), ('Palabra', 'irure'), ('Palabra', 'dolor'), ('Palabra', 'in'), ('Palabra', 'reprehenderit'), ('Palabra', 'in'), ('Palabra', 'voluptate'), ('Palabra', 'velit'), ('Palabra', 'esse'), ('Palabra', 'cillum'), ('Palabra', 'dolore'), ('Palabra', 'eu'), ('Palabra', 'fugiat'), ('Palabra', 'nulla'), ('Palabra', 'pariatur'), ('Signo de puntuacion', '.'), ('Palabra', 'Excepteur'), ('Palabra', 'sint'), ('Palabra', 'occaecat'), ('Palabra', 'cupidatat'), ('Palabra', 'non'), ('Palabra', 'proident'), ('Signo de puntuacion', ','), ('Palabra', 'sunt'), ('Palabra', 'in'), ('Palabra', 'culpa'), ('Palabra', 'qui'), ('Palabra', 'officia'), ('Palabra', 'deserunt'), ('Palabra', 'mollit'), ('Palabra', 'anim'), ('Palabra', 'id'), ('Palabra', 'est'), ('Palabra', 'laborum'), ('Signo de puntuacion', '.'), ('Palabra en ingles', 'hi'), ('Pregunta en ingles', 'what')]\n",
      "Errores encontrados:\n",
      "[('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' ')]\n"
     ]
    }
   ],
   "source": [
    "def tokenizador(archivo):\n",
    "    i = 0\n",
    "    while i < len(archivo):\n",
    "        if archivo[i] in abecedario:\n",
    "            palabra = \"\"\n",
    "            while i < len(archivo) and archivo[i] in abecedario:\n",
    "                palabra += archivo[i]\n",
    "                i += 1\n",
    "            if palabra in palabras_reservadas:\n",
    "                tokens.append(palabra)\n",
    "            elif palabra in En_words:\n",
    "                tokens.append(palabra)\n",
    "            elif palabra in Es_words:\n",
    "                tokens.append(palabra)\n",
    "            elif palabra in En_questions:\n",
    "                tokens.append(palabra)\n",
    "            elif palabra in Es_questions:\n",
    "                tokens.append(palabra)\n",
    "            else:\n",
    "                tokens.append(palabra)\n",
    "        elif archivo[i] in numeros:\n",
    "            numero = \"\"\n",
    "            while i < len(archivo) and archivo[i] in numeros:\n",
    "                numero += archivo[i]\n",
    "                i += 1\n",
    "            tokens.append(numero)\n",
    "        elif archivo[i] in signos_puntuacion:\n",
    "            tokens.append(archivo[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            errores.append(archivo[i])\n",
    "            i += 1\n",
    "print(\"Tokens encontrados:\")\n",
    "print(tokens)\n",
    "print(\"Errores encontrados:\")\n",
    "print(errores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens encontrados:\n",
      "Palabra: Hola\n",
      "Palabra: Mundo\n",
      "Signo de puntuacion: !\n",
      "Numero: 1\n",
      "Signo de puntuacion: ,\n",
      "Signo de puntuacion: .\n",
      "Signo de puntuacion: :\n",
      "Signo de puntuacion: ;\n",
      "Palabra: print\n",
      "Palabra: init\n",
      "Palabra: if\n",
      "Signo de puntuacion: #\n",
      "Palabra: Lorem\n",
      "Palabra: ipsum\n",
      "Palabra: dolor\n",
      "Palabra: sit\n",
      "Palabra: amet\n",
      "Signo de puntuacion: ,\n",
      "Palabra: consectetur\n",
      "Palabra: adipiscing\n",
      "Palabra: elit\n",
      "Signo de puntuacion: ,\n",
      "Palabra: sed\n",
      "Palabra: do\n",
      "Palabra: eiusmod\n",
      "Palabra: tempor\n",
      "Palabra: incididunt\n",
      "Palabra: ut\n",
      "Palabra: labore\n",
      "Palabra: et\n",
      "Palabra: dolore\n",
      "Palabra: magna\n",
      "Palabra: aliqua\n",
      "Signo de puntuacion: .\n",
      "Palabra: Ut\n",
      "Palabra: enim\n",
      "Palabra: ad\n",
      "Palabra: minim\n",
      "Palabra: veniam\n",
      "Signo de puntuacion: ,\n",
      "Palabra: quis\n",
      "Palabra: nostrud\n",
      "Palabra: exercitation\n",
      "Palabra: ullamco\n",
      "Palabra: laboris\n",
      "Palabra: nisi\n",
      "Palabra: ut\n",
      "Palabra: aliquip\n",
      "Palabra: ex\n",
      "Palabra: ea\n",
      "Palabra: commodo\n",
      "Palabra: consequat\n",
      "Signo de puntuacion: .\n",
      "Palabra: Duis\n",
      "Palabra: aute\n",
      "Palabra: irure\n",
      "Palabra: dolor\n",
      "Palabra: in\n",
      "Palabra: reprehenderit\n",
      "Palabra: in\n",
      "Palabra: voluptate\n",
      "Palabra: velit\n",
      "Palabra: esse\n",
      "Palabra: cillum\n",
      "Palabra: dolore\n",
      "Palabra: eu\n",
      "Palabra: fugiat\n",
      "Palabra: nulla\n",
      "Palabra: pariatur\n",
      "Signo de puntuacion: .\n",
      "Palabra: Excepteur\n",
      "Palabra: sint\n",
      "Palabra: occaecat\n",
      "Palabra: cupidatat\n",
      "Palabra: non\n",
      "Palabra: proident\n",
      "Signo de puntuacion: ,\n",
      "Palabra: sunt\n",
      "Palabra: in\n",
      "Palabra: culpa\n",
      "Palabra: qui\n",
      "Palabra: officia\n",
      "Palabra: deserunt\n",
      "Palabra: mollit\n",
      "Palabra: anim\n",
      "Palabra: id\n",
      "Palabra: est\n",
      "Palabra: laborum\n",
      "Signo de puntuacion: .\n",
      "Palabra en ingles: hi\n",
      "Pregunta en ingles: what\n",
      "Errores encontrados:\n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error: \n",
      "\n",
      "Error: \n",
      "\n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error: \n",
      "\n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error: \n",
      "\n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error: \n",
      "\n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error: \n",
      "\n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error: \n",
      "\n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n",
      "Error:  \n"
     ]
    }
   ],
   "source": [
    "with open(\"pruebadetexto.txt\", \"r\") as f:\n",
    "    archivo = f.read()\n",
    "def tokenizador(archivo):\n",
    "    tokens = []\n",
    "    errores = []\n",
    "    i = 0\n",
    "    while i < len(archivo):\n",
    "        if archivo[i] in abecedario:\n",
    "            palabra = \"\"\n",
    "            while i < len(archivo) and archivo[i] in abecedario:\n",
    "                palabra += archivo[i]\n",
    "                i += 1\n",
    "            if palabra in palabras_reservadas:\n",
    "                tokens.append((\"Palabra reservada\", palabra))\n",
    "            elif palabra in En_words:\n",
    "                tokens.append((\"Palabra en ingles\", palabra))\n",
    "            elif palabra in Es_words:\n",
    "                tokens.append((\"Palabra en español\", palabra))\n",
    "            elif palabra in En_questions:\n",
    "                tokens.append((\"Pregunta en ingles\", palabra))\n",
    "            elif palabra in Es_questions:\n",
    "                tokens.append((\"Pregunta en español\", palabra))\n",
    "            else:\n",
    "                tokens.append((\"Palabra\", palabra))\n",
    "        elif archivo[i] in numeros:\n",
    "            numero = \"\"\n",
    "            while i < len(archivo) and archivo[i] in numeros:\n",
    "                numero += archivo[i]\n",
    "                i += 1\n",
    "            tokens.append((\"Numero\", numero))\n",
    "        elif archivo[i] in signos_puntuacion:\n",
    "            tokens.append((\"Signo de puntuacion\", archivo[i]))\n",
    "            i += 1\n",
    "        else:\n",
    "            errores.append((\"Error\", archivo[i]))\n",
    "            i += 1\n",
    "    return tokens, errores\n",
    "\n",
    "tokens, errores = tokenizador(archivo)\n",
    "\n",
    "print(\"Tokens encontrados:\")\n",
    "for token_type, token in tokens:\n",
    "    print(f\"{token_type}: {token}\")\n",
    "\n",
    "print(\"Errores encontrados:\")\n",
    "for error_type, error in errores:\n",
    "    print(f\"{error_type}: {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola -> Palabra\n",
      "Mundo -> Palabra\n",
      "! -> Signo de puntuacion\n",
      "1 -> Numero\n",
      ", -> Signo de puntuacion\n",
      ". -> Signo de puntuacion\n",
      ": -> Signo de puntuacion\n",
      "; -> Signo de puntuacion\n",
      "print -> Palabra\n",
      "init -> Palabra\n",
      "if -> Palabra\n",
      "# -> Signo de puntuacion\n",
      "Lorem -> Palabra\n",
      "ipsum -> Palabra\n",
      "dolor -> Palabra\n",
      "sit -> Palabra\n",
      "amet -> Palabra\n",
      ", -> Signo de puntuacion\n",
      "consectetur -> Palabra\n",
      "adipiscing -> Palabra\n",
      "elit -> Palabra\n",
      ", -> Signo de puntuacion\n",
      "sed -> Palabra\n",
      "do -> Palabra\n",
      "eiusmod -> Palabra\n",
      "tempor -> Palabra\n",
      "incididunt -> Palabra\n",
      "ut -> Palabra\n",
      "labore -> Palabra\n",
      "et -> Palabra\n",
      "dolore -> Palabra\n",
      "magna -> Palabra\n",
      "aliqua -> Palabra\n",
      ". -> Signo de puntuacion\n",
      "Ut -> Palabra\n",
      "enim -> Palabra\n",
      "ad -> Palabra\n",
      "minim -> Palabra\n",
      "veniam -> Palabra\n",
      ", -> Signo de puntuacion\n",
      "quis -> Palabra\n",
      "nostrud -> Palabra\n",
      "exercitation -> Palabra\n",
      "ullamco -> Palabra\n",
      "laboris -> Palabra\n",
      "nisi -> Palabra\n",
      "ut -> Palabra\n",
      "aliquip -> Palabra\n",
      "ex -> Palabra\n",
      "ea -> Palabra\n",
      "commodo -> Palabra\n",
      "consequat -> Palabra\n",
      ". -> Signo de puntuacion\n",
      "Duis -> Palabra\n",
      "aute -> Palabra\n",
      "irure -> Palabra\n",
      "dolor -> Palabra\n",
      "in -> Palabra\n",
      "reprehenderit -> Palabra\n",
      "in -> Palabra\n",
      "voluptate -> Palabra\n",
      "velit -> Palabra\n",
      "esse -> Palabra\n",
      "cillum -> Palabra\n",
      "dolore -> Palabra\n",
      "eu -> Palabra\n",
      "fugiat -> Palabra\n",
      "nulla -> Palabra\n",
      "pariatur -> Palabra\n",
      ". -> Signo de puntuacion\n",
      "Excepteur -> Palabra\n",
      "sint -> Palabra\n",
      "occaecat -> Palabra\n",
      "cupidatat -> Palabra\n",
      "non -> Palabra\n",
      "proident -> Palabra\n",
      ", -> Signo de puntuacion\n",
      "sunt -> Palabra\n",
      "in -> Palabra\n",
      "culpa -> Palabra\n",
      "qui -> Palabra\n",
      "officia -> Palabra\n",
      "deserunt -> Palabra\n",
      "mollit -> Palabra\n",
      "anim -> Palabra\n",
      "id -> Palabra\n",
      "est -> Palabra\n",
      "laborum -> Palabra\n",
      ". -> Signo de puntuacion\n",
      "hi -> Palabra en ingles\n",
      "what -> Pregunta en ingles\n"
     ]
    }
   ],
   "source": [
    "#analiza el lexico del archivo y imprime los tokens\n",
    "def analizador_lexico(archivo):\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    while i < len(archivo):\n",
    "        if archivo[i] in abecedario:\n",
    "            lexema = \"\"\n",
    "            while i < len(archivo) and archivo[i] in abecedario:\n",
    "                lexema += archivo[i]\n",
    "                i += 1\n",
    "            if lexema in palabras_reservadas:\n",
    "                tokens.append(lexema + \" -> Palabra reservada\")\n",
    "            else:\n",
    "                if lexema in En_words:\n",
    "                    tokens.append(lexema + \" -> Palabra en ingles\")\n",
    "                elif lexema in Es_words:\n",
    "                    tokens.append(lexema + \" -> Palabra en español\")\n",
    "                elif lexema in En_questions:\n",
    "                    tokens.append(lexema + \" -> Pregunta en ingles\")\n",
    "                elif lexema in Es_questions:\n",
    "                    tokens.append(lexema + \" -> Pregunta en español\")\n",
    "                else:\n",
    "                    tokens.append(lexema + \" -> Palabra\")\n",
    "        elif archivo[i] in numeros:\n",
    "            lexema = \"\"\n",
    "            while i < len(archivo) and archivo[i] in numeros:\n",
    "                lexema += archivo[i]\n",
    "                i += 1\n",
    "            tokens.append(lexema + \" -> Numero\")\n",
    "        elif archivo[i] in signos_puntuacion:\n",
    "            tokens.append(archivo[i] + \" -> Signo de puntuacion\")\n",
    "            i += 1\n",
    "        else:\n",
    "            errores.append(archivo[i])\n",
    "            i += 1\n",
    "    return tokens\n",
    "\n",
    "def imprimir_lexico(archivo):\n",
    "    tokens = analizador_lexico(archivo)\n",
    "    for token in tokens:\n",
    "        print(token)\n",
    "\n",
    "imprimir_lexico(abrir_archivo('pruebadetexto.txt'))\n",
    "\n",
    "#guarda la salida en forma de diccionario \n",
    "def guardar_lista(archivo, sobrescribir=True):\n",
    "    tokens = analizador_lexico(archivo)\n",
    "    mode = 'w' if sobrescribir else 'a'  # Si sobrescribir es True, se abrirá el archivo en modo escritura, si no, se abrirá en modo de añadir al final\n",
    "    with open('output.txt', mode) as f:\n",
    "        for token in tokens:\n",
    "            f.write(token + \" \")\n",
    "guardar_lista(abrir_archivo('pruebadetexto.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lexema': 'Hola', 'tipo': 'Palabra'}\n",
      "{'lexema': 'Mundo', 'tipo': 'Palabra'}\n",
      "{'lexema': '!', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': '1', 'tipo': 'Numero'}\n",
      "{'lexema': ',', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': '.', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': ':', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': ';', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'print', 'tipo': 'Palabra'}\n",
      "{'lexema': 'init', 'tipo': 'Palabra'}\n",
      "{'lexema': 'if', 'tipo': 'Palabra'}\n",
      "{'lexema': '#', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'Lorem', 'tipo': 'Palabra'}\n",
      "{'lexema': 'ipsum', 'tipo': 'Palabra'}\n",
      "{'lexema': 'dolor', 'tipo': 'Palabra'}\n",
      "{'lexema': 'sit', 'tipo': 'Palabra'}\n",
      "{'lexema': 'amet', 'tipo': 'Palabra'}\n",
      "{'lexema': ',', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'consectetur', 'tipo': 'Palabra'}\n",
      "{'lexema': 'adipiscing', 'tipo': 'Palabra'}\n",
      "{'lexema': 'elit', 'tipo': 'Palabra'}\n",
      "{'lexema': ',', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'sed', 'tipo': 'Palabra'}\n",
      "{'lexema': 'do', 'tipo': 'Palabra'}\n",
      "{'lexema': 'eiusmod', 'tipo': 'Palabra'}\n",
      "{'lexema': 'tempor', 'tipo': 'Palabra'}\n",
      "{'lexema': 'incididunt', 'tipo': 'Palabra'}\n",
      "{'lexema': 'ut', 'tipo': 'Palabra'}\n",
      "{'lexema': 'labore', 'tipo': 'Palabra'}\n",
      "{'lexema': 'et', 'tipo': 'Palabra'}\n",
      "{'lexema': 'dolore', 'tipo': 'Palabra'}\n",
      "{'lexema': 'magna', 'tipo': 'Palabra'}\n",
      "{'lexema': 'aliqua', 'tipo': 'Palabra'}\n",
      "{'lexema': '.', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'Ut', 'tipo': 'Palabra'}\n",
      "{'lexema': 'enim', 'tipo': 'Palabra'}\n",
      "{'lexema': 'ad', 'tipo': 'Palabra'}\n",
      "{'lexema': 'minim', 'tipo': 'Palabra'}\n",
      "{'lexema': 'veniam', 'tipo': 'Palabra'}\n",
      "{'lexema': ',', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'quis', 'tipo': 'Palabra'}\n",
      "{'lexema': 'nostrud', 'tipo': 'Palabra'}\n",
      "{'lexema': 'exercitation', 'tipo': 'Palabra'}\n",
      "{'lexema': 'ullamco', 'tipo': 'Palabra'}\n",
      "{'lexema': 'laboris', 'tipo': 'Palabra'}\n",
      "{'lexema': 'nisi', 'tipo': 'Palabra'}\n",
      "{'lexema': 'ut', 'tipo': 'Palabra'}\n",
      "{'lexema': 'aliquip', 'tipo': 'Palabra'}\n",
      "{'lexema': 'ex', 'tipo': 'Palabra'}\n",
      "{'lexema': 'ea', 'tipo': 'Palabra'}\n",
      "{'lexema': 'commodo', 'tipo': 'Palabra'}\n",
      "{'lexema': 'consequat', 'tipo': 'Palabra'}\n",
      "{'lexema': '.', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'Duis', 'tipo': 'Palabra'}\n",
      "{'lexema': 'aute', 'tipo': 'Palabra'}\n",
      "{'lexema': 'irure', 'tipo': 'Palabra'}\n",
      "{'lexema': 'dolor', 'tipo': 'Palabra'}\n",
      "{'lexema': 'in', 'tipo': 'Palabra'}\n",
      "{'lexema': 'reprehenderit', 'tipo': 'Palabra'}\n",
      "{'lexema': 'in', 'tipo': 'Palabra'}\n",
      "{'lexema': 'voluptate', 'tipo': 'Palabra'}\n",
      "{'lexema': 'velit', 'tipo': 'Palabra'}\n",
      "{'lexema': 'esse', 'tipo': 'Palabra'}\n",
      "{'lexema': 'cillum', 'tipo': 'Palabra'}\n",
      "{'lexema': 'dolore', 'tipo': 'Palabra'}\n",
      "{'lexema': 'eu', 'tipo': 'Palabra'}\n",
      "{'lexema': 'fugiat', 'tipo': 'Palabra'}\n",
      "{'lexema': 'nulla', 'tipo': 'Palabra'}\n",
      "{'lexema': 'pariatur', 'tipo': 'Palabra'}\n",
      "{'lexema': '.', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'Excepteur', 'tipo': 'Palabra'}\n",
      "{'lexema': 'sint', 'tipo': 'Palabra'}\n",
      "{'lexema': 'occaecat', 'tipo': 'Palabra'}\n",
      "{'lexema': 'cupidatat', 'tipo': 'Palabra'}\n",
      "{'lexema': 'non', 'tipo': 'Palabra'}\n",
      "{'lexema': 'proident', 'tipo': 'Palabra'}\n",
      "{'lexema': ',', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'sunt', 'tipo': 'Palabra'}\n",
      "{'lexema': 'in', 'tipo': 'Palabra'}\n",
      "{'lexema': 'culpa', 'tipo': 'Palabra'}\n",
      "{'lexema': 'qui', 'tipo': 'Palabra'}\n",
      "{'lexema': 'officia', 'tipo': 'Palabra'}\n",
      "{'lexema': 'deserunt', 'tipo': 'Palabra'}\n",
      "{'lexema': 'mollit', 'tipo': 'Palabra'}\n",
      "{'lexema': 'anim', 'tipo': 'Palabra'}\n",
      "{'lexema': 'id', 'tipo': 'Palabra'}\n",
      "{'lexema': 'est', 'tipo': 'Palabra'}\n",
      "{'lexema': 'laborum', 'tipo': 'Palabra'}\n",
      "{'lexema': '.', 'tipo': 'Signo de puntuacion'}\n",
      "{'lexema': 'hi', 'tipo': 'Palabra en ingles'}\n",
      "{'lexema': 'what', 'tipo': 'Pregunta en ingles'}\n"
     ]
    }
   ],
   "source": [
    "def analizador_lexico(archivo):\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    while i < len(archivo):\n",
    "        if archivo[i] in abecedario:\n",
    "            lexema = \"\"\n",
    "            while i < len(archivo) and archivo[i] in abecedario:\n",
    "                lexema += archivo[i]\n",
    "                i += 1\n",
    "            if lexema in palabras_reservadas:\n",
    "                tokens.append({\"lexema\": lexema, \"tipo\": \"Palabra reservada\"})\n",
    "            else:\n",
    "                if lexema in En_words:\n",
    "                    tokens.append({\"lexema\": lexema, \"tipo\": \"Palabra en ingles\"})\n",
    "                elif lexema in Es_words:\n",
    "                    tokens.append({\"lexema\": lexema, \"tipo\": \"Palabra en español\"})\n",
    "                elif lexema in En_questions:\n",
    "                    tokens.append({\"lexema\": lexema, \"tipo\": \"Pregunta en ingles\"})\n",
    "                elif lexema in Es_questions:\n",
    "                    tokens.append({\"lexema\": lexema, \"tipo\": \"Pregunta en español\"})\n",
    "                else:\n",
    "                    tokens.append({\"lexema\": lexema, \"tipo\": \"Palabra\"})\n",
    "        elif archivo[i] in numeros:\n",
    "            lexema = \"\"\n",
    "            while i < len(archivo) and archivo[i] in numeros:\n",
    "                lexema += archivo[i]\n",
    "                i += 1\n",
    "            tokens.append({\"lexema\": lexema, \"tipo\": \"Numero\"})\n",
    "        elif archivo[i] in signos_puntuacion:\n",
    "            tokens.append({\"lexema\": archivo[i], \"tipo\": \"Signo de puntuacion\"})\n",
    "            i += 1\n",
    "        else:\n",
    "            errores.append(archivo[i])\n",
    "            i += 1\n",
    "    return tokens\n",
    "\n",
    "def imprimir_lexico(archivo):\n",
    "    tokens = analizador_lexico(archivo)\n",
    "    for token in tokens:\n",
    "        print(token)\n",
    "\n",
    "imprimir_lexico(abrir_archivo('pruebadetexto.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_diccionario(archivo, sobrescribir=True):\n",
    "    tokens = analizador_lexico(archivo)\n",
    "    mode = 'w' if sobrescribir else 'a'  # Si sobrescribir es True, se abrirá el archivo en modo escritura, si no, se abrirá en modo de añadir al final\n",
    "    with open('output.txt', mode) as f:\n",
    "        for token in tokens:\n",
    "            f.write(str(token) + \"\\n\")\n",
    "guardar_diccionario(abrir_archivo('pruebadetexto.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errores:  [('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', '\\n'), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ('Error', ' '), ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Errores: \", errores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
